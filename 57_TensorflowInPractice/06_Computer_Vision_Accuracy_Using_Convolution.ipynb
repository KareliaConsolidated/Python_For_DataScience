{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.4969 - accuracy: 0.8247\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3729 - accuracy: 0.8652\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.3374 - accuracy: 0.8766\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.3127 - accuracy: 0.8857\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2940 - accuracy: 0.8921\n",
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.3571 - accuracy: 0.8712\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images=training_images / 255.0\n",
    "test_images=test_images / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions in Short\n",
    "<br/>\n",
    "<div style=\"text-align: justify\">In short, you take an array (usually 3x3 or 5x5) and pass it over the image. By changing the underlying pixels based on the formula within that matrix, you can do things like edge detection. So, for example, if you look at the above link, you'll see a 3x3 that is defined for edge detection where the middle cell is 8, and all of its neighbors are -1. In this case, for each pixel, you would multiply its value by 8, then subtract the value of each neighbor. Do this for every pixel, and you'll end up with a new image that has the edges enhanced.</div>\n",
    "<br/>\n",
    "<div style=\"text-align: justify\">This is perfect for computer vision, because often it's features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less...because you'll just train on the highlighted features.</div>\n",
    "<br/>\n",
    "<div style=\"text-align: justify\">That's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.4441 - accuracy: 0.8390\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.2985 - accuracy: 0.8900\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.2527 - accuracy: 0.9067\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.2212 - accuracy: 0.9169\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.1958 - accuracy: 0.9268\n",
      "10000/10000 [==============================] - 4s 437us/sample - loss: 0.2691 - accuracy: 0.9072\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "\n",
    "training_images=training_images / 255.0\n",
    "\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "\n",
    "test_images=test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Convolutions and Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
      " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
      " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=26\n",
    "CONVOLUTION_NUMBER = 1\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[0,x].grid(False)\n",
    "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[1,x].grid(False)\n",
    "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 28s 465us/sample - loss: 0.1581 - accuracy: 0.9526\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 29s 480us/sample - loss: 0.0532 - accuracy: 0.9837\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 27s 449us/sample - loss: 0.0347 - accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 27s 458us/sample - loss: 0.0230 - accuracy: 0.9924\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 28s 467us/sample - loss: 0.0157 - accuracy: 0.9948\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 27s 455us/sample - loss: 0.0114 - accuracy: 0.9965\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 27s 458us/sample - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 28s 468us/sample - loss: 0.0071 - accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 28s 463us/sample - loss: 0.0054 - accuracy: 0.9984\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 27s 454us/sample - loss: 0.0054 - accuracy: 0.9982\n",
      "10000/10000 [==============================] - 2s 174us/sample - loss: 0.0493 - accuracy: 0.9870\n",
      "0.987\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
